--- 
title: "Reinforcement Learning"
subtitle: "Ciencia de los Datos Financieros"
author: "Synergy Vision"
date: "2018-12-05"
knit: "bookdown::render_book"
documentclass: krantz
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: yes
lof: yes
fontsize: 12pt
monofontoptions: "Scale=0.8"
keep_md: yes
site: bookdown::bookdown_site
description: ""
url: 'http\://synergy.vision/Reinforcement-learning/'
github-repo: synergyvision/Reinforcement-learning/
cover-image: images/cover.png
---

# Prefacio {-}

Placeholder


## ¿Por qué  leer este libro? {-}
## Estructura del libro {-}
## Información sobre los programas y convenciones {-}
## Prácticas interactivas con R {-}
## Agradecimientos {-}

<!--chapter:end:index.Rmd-->


# Acerca del Autor {-}

Este material es un esfuerzo de equipo en Synergy Vision, (<http://synergy.vision/nosotros/>).		 

El propósito de este material es ofrecer una experiencia de aprendizaje distinta y enfocada en el estudiante. El propósito es que realmente aprenda y practique con mucha intensidad. La idea es cambiar el modelo de clases magistrales y ofrecer una experiencia más centrada en el estudiante y menos centrado en el profesor. Para los temas más técnicos y avanzados es necesario trabajar de la mano con el estudiante y asistirlo en el proceso de aprendizaje con prácticas guiadas, material en línea e interactivo, videos, evaluación contínua de brechas y entendimiento, entre otros, para procurar el dominio de la materia.
  		  
Nuestro foco es la Ciencia de los Datos Financieros y para ello se desarrollará material sobre: **Probabilidad y Estadística Matemática en R**, **Programación Científica en R**, **Mercados**, **Inversiones y Trading**, **Datos y Modelos Financieros en R**, **Renta Fija**, **Inmunización de Carteras de Renta Fija**, **Teoría de Riesgo en R**, **Finanzas Cuantitativas**, **Ingeniería Financiera**, **Procesos Estocásticos en R**, **Series de Tiempo en R**, **Ciencia de los Datos**, **Ciencia de los Datos Financieros**, **Simulación en R**, **Desarrollo de Aplicaciones Interactivas en R**, **Minería de Datos**, **Aprendizaje Estadístico**, **Estadística Multivariante**, **Riesgo de Crédito**, **Riesgo de Liquidez**, **Riesgo de Mercado**, **Riesgo Operacional**, **Riesgo de Cambio**, **Análisis Técnico**, **Inversión Visual**, **Finanzas**, **Finanzas Corporativas**, **Valoración**, **Teoría de Portafolio**, entre otros.

Nuestra cuenta de Twitter es (https://twitter.com/bysynergyvision) y nuestros repositorios están en GitHub (https://github.com/synergyvision).
  		  
 **Somos Científicos de Datos Financieros**

<!--chapter:end:000-author.Rmd-->


# Introducción 

Placeholder


## Reinforcement Learning
## Ejemplos
## Elementos del Reinforcement Learning
## Limitaciones y alcance
## Un ejemplo clásico: tres en linea.     

<!--chapter:end:010-introduction.Rmd-->


# Bandido multibrazo

Placeholder


## Un problema de bandido k-brasos
## Métodos de acción valor
## Pruebas sobre el problema del bandido de 10 brasos
## Aplicación progresiva
## Problemas no estacionarios
## óptimos valores iniciales
## Cota superior de confianza en la selección de acciones (CSC)
## Algoritmo del gradiente
## Investigación asociativa

<!--chapter:end:100-capitulo1.Rmd-->


# Procesos de decision de Markov finitos

Placeholder


##  El agente, Un interface del entorno
## Metas y recompensas.
## Retornos y episodios
## Notación unificada tanto para tareas episodicas y continuas.
## Políticas y funciones de valor
## Funciones de valor y políticas optimas
## Optimalidad y aproximación

<!--chapter:end:200-capitulo2.Rmd-->


# Programación dinámica

Placeholder


## Políticas evaluadas (Predicción)
## Mejora de las políticas
## Iteración de políticas
## Iteración de valores 
## Programación dinámica asincrónica.
## Iteración generalizada de políticas
## Eficiencia de la programación dinámica

<!--chapter:end:201-capitulo3.Rmd-->


# Métodos de Montecarlo

Placeholder


## Predicción con Monte Carlo
## Estimación de Monte Carlo de los Valores de Acción
## Métodos de Monte Carlo con control
## Métodos de Monte Carlo con control sin iniciar exploración
## Predicciones no políticas via muestreos de importancia.
## Implementación incremental
## Monte Carlo no político con control

<!--chapter:end:202-capitulo4.Rmd-->


# Aprendizaje por Diferencia Temporal

Placeholder


## Predicción
## Ventajas de los métodos de predicción de TD
## Calidad de TD(0)
## Sarsa: TD político con control 
## Q-Learning: TD no político con control 
## Sarsa esparada
## Sesgo de maximización y doble aprendizaje
## Juegos, afterstates y otros casos especiales

<!--chapter:end:203-capitulo5.Rmd-->


# Bootstrapping en $n$-pasos

Placeholder


## Predicción de TD en $n$ pasos

<!--chapter:end:204-capitulo6.Rmd-->


# (APPENDIX) Apéndice {-}

Placeholder

# Software Tools

Placeholder


## R and R packages
## Pandoc
## LaTeX

<!--chapter:end:400-apendice.Rmd-->

# Referencias {-}




<!--chapter:end:500-references.Rmd-->

